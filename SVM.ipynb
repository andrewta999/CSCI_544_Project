{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03326ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim.downloader as api\n",
    "import contractions\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ed0108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoty_file = './data/US_category_id.json'\n",
    "video_file = './data/USvideos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "632c412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cat_df = pd.read_json(categoty_file)\n",
    "raw_vid_df = pd.read_csv(video_file, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90b48f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_struct = json.loads(raw_cat_df.to_json(orient=\"records\"))    \n",
    "category_flat = pd.json_normalize(json_struct) #use pd.io.json\n",
    "categories = category_flat[['items.id', 'items.snippet.title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db7efb0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = raw_vid_df[['title', 'category_id']].copy()\n",
    "df = df.dropna()\n",
    "\n",
    "df['category_id'] = df['category_id'].apply(lambda x: int(x))\n",
    "df['title'] = df['title'] + ' ' + raw_vid_df['channel_title'] + ' ' + raw_vid_df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6040d5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean data\n",
    "def clean_data(corpus):\n",
    "    # convert to lower case and remove space\n",
    "    corpus['title'] = corpus['title'].apply(lambda x: x.lower().strip())\n",
    "\n",
    "    # perform contractions\n",
    "    corpus['title'] = corpus['title'].apply(lambda x: ' '.join(contractions.fix(word) for word in x.split()))\n",
    "\n",
    "    # corpus[review] = corpus[review].apply(lambda x: re.sub(r'\\b(?:not|never|no)\\b[\\w\\s]+[^w\\s]', \n",
    "    #                                                         lambda match: re.sub(r'(\\s+)(\\w+)', r'\\1NOT_\\2', match.group(0)),x))\n",
    "\n",
    "    # remove non alphabet characters\n",
    "    corpus['title'] = corpus['title'].apply(lambda x: re.sub(r'[^a-zA-Z]', ' ', x))\n",
    "\n",
    "\n",
    "    # remove extra space in between words\n",
    "    corpus['title'] = corpus['title'].apply(lambda x: re.sub(' +', ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c223b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize each word for each review\n",
    "def tokenize_string(x):\n",
    "    res = [word_tokenize(s) for s in x]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b34773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess words from the dataset that exist in the google database\n",
    "def exist_in_google(X):\n",
    "    reviews = tokenize_string(X)\n",
    "    res = {}\n",
    "    \n",
    "    for review in reviews:\n",
    "        for word in review:\n",
    "            if word not in res:\n",
    "                try:\n",
    "                    res[word] = wv[word]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    return res, reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f18948e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Word2Vec features from the Google dataset given the Amazon reviews\n",
    "def vectorize(X, y, exist_dict, tokens):\n",
    "    X_new = []\n",
    "    index_to_remove = []\n",
    "\n",
    "    for idx, review in zip(X.index, tokens):\n",
    "        total = [0,]\n",
    "        length = 0\n",
    "        for word in review:\n",
    "            if word in exist_dict:\n",
    "                total += exist_dict[word]\n",
    "                length += 1\n",
    "        if length > 0:\n",
    "            X_new.append(total / length)\n",
    "        else:\n",
    "            index_to_remove.append(idx)\n",
    "        \n",
    "    # remove empty words from Y\n",
    "    y_new = y.drop(labels=index_to_remove)\n",
    "    \n",
    "    return X_new, y_new           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f7f8c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "690579ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "192c6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fce9beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict of all words that exist in the Google model as well as the tokenized reviews\n",
    "exist_dict, tokens = exist_in_google(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c336798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_g, y_g = vectorize(X, y, exist_dict, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "730cc554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_g, y_g, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac001790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.60      0.66       463\n",
      "           2       0.89      0.83      0.86        66\n",
      "          10       0.86      0.92      0.89      1290\n",
      "          15       0.84      0.97      0.90       172\n",
      "          17       0.89      0.95      0.92       420\n",
      "          19       0.91      0.88      0.90        83\n",
      "          20       0.97      0.89      0.93       170\n",
      "          22       0.61      0.41      0.49       618\n",
      "          23       0.69      0.65      0.67       682\n",
      "          24       0.70      0.72      0.71      2006\n",
      "          25       0.87      0.88      0.87       510\n",
      "          26       0.75      0.84      0.79       868\n",
      "          27       0.79      0.82      0.81       336\n",
      "          28       0.73      0.77      0.75       484\n",
      "          29       1.00      0.73      0.84        11\n",
      "          43       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.77      8189\n",
      "   macro avg       0.83      0.79      0.80      8189\n",
      "weighted avg       0.76      0.77      0.76      8189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(dual=False)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_prediction = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, svm_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770284b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
